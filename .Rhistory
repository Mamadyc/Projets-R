## Projet Tutoré 2
##Prédire la mortalité hospitalière à l'aide d'un modèle de machine learning (ou deep learning)
# Charger les bibliothèques nécessaires
library(tidyverse)
library(caret)
library(xgboost)
install.packages("caret")
library(xgboost)
install.packages("xgboost")
library(xgboost)
# Charger les données
data <- read.csv('dataPT2.csv.gz', header = TRUE, stringsAsFactors = FALSE)
dataPT2.csv <- read.csv2("C:/Users/conde/Downloads/dataPT2.csv.gz")
View(dataPT2.csv)
cahierVariables <- read.csv("C:/Users/conde/Downloads/cahierVariables.csv")
View(cahierVariables)
View(dataPT2.csv)
View(dataPT2.csv)
Str(dataPT2.csv)
head(dataPT2.csv)
str(dataPT2.csv)
# Supprimer les colonnes inutiles
colonne sup  <- c('ethnicity', 'encounter_id', 'hospital_id', 'icu_id', 'patient_id', 'apache_4a_icu_death_prob', 'apache_4a_hospital_death_prob')
# Supprimer les colonnes inutiles
colonne-sup  <- c('ethnicity', 'encounter_id', 'hospital_id', 'icu_id', 'patient_id', 'apache_4a_icu_death_prob', 'apache_4a_hospital_death_prob')
# Supprimer les colonnes inutiles
colonne-sup  <- c('ethnicity', 'encounter_id', 'hospital_id', 'icu_id', 'patient_id', 'apache_4a_icu_death_prob', 'apache_4a_hospital_death_prob')
# Supprimer les colonnes inutiles
colonne-sup  = c('ethnicity', 'encounter_id', 'hospital_id', 'icu_id', 'patient_id', 'apache_4a_icu_death_prob', 'apache_4a_hospital_death_prob')
# Supprimer les colonnes inutiles
colonne-sup <- c('ethnicity', 'encounter_id', 'hospital_id', 'icu_id', 'patient_id', 'apache_4a_icu_death_prob', 'apache_4a_hospital_death_prob')
colonne-sup <- c('ethnicity', 'encounter_id', 'hospital_id', 'icu_id', 'patient_id', 'apache_4a_icu_death_prob', 'apache_4a_hospital_death_prob')
colonne-sup <- c('ethnicity', 'encounter_id', 'hospital_id', 'icu_id', 'patient_id', 'apache_4a_icu_death_prob', 'apache_4a_hospital_death_prob')
colonne-sup <-dataPT2.csv[,-c('ethnicity', 'encounter_id', 'hospital_id', 'icu_id', 'patient_id', 'apache_4a_icu_death_prob', 'apache_4a_hospital_death_prob')]
colonne-sup <-dataPT2.csv[,-c('ethnicity', 'encounter_id', 'hospital_id', 'icu_id', 'patient_id', 'apache_4a_icu_death_prob', 'apache_4a_hospital_death_prob')]
colonne_sup <- c('ethnicity', 'encounter_id', 'hospital_id', 'icu_id', 'patient_id', 'apache_4a_icu_death_prob', 'apache_4a_hospital_death_prob')
# Supprimer les colonnes inutiles
data <- data[, !(names(data) %in% colonne_sup)]
# Supprimer les colonnes inutiles
data <- dataPT2.csv[, !(names(dataPT2.csv) %in% colonne_sup)]
View(data)
View(data)
View(data)
str(data)
data[is.na(data)] <- 0
View(data)
View(data)
summary(data$bmi)
data$gender <- ifelse(data$gender == 'm', 1, ifelse(data$gender == 'f', 0, data$gender))
View(data)
View(dataPT2.csv)
View(data)
data$gender <- ifelse(data$gender == 'M', 1, ifelse(data$gender == 'F', 0, data$gender))
## Projet Tutoré 2
##Prédire la mortalité hospitalière à l'aide d'un modèle de machine learning (ou deep learning)
# Charger les bibliothèques nécessaires
library(tidyverse)
library(caret)
library(xgboost)
# Charger les donnée
dataPT2.csv <- read.csv("C:/Users/conde/Downloads/dataPT2.csv.gz")
str(data)
data <- dataPT2.csv[, !(names(dataPT2.csv) %in% colonne_sup)]
data <- data.frame(lapply(data, function(x) ifelse(is.na(x), 0, x)))
data$gender <- ifelse(data$gender == 'M', 1, ifelse(data$gender == 'F', 0, data$gender))
data$gender <- ifelse(data$gender == 'M', 1, ifelse(data$gender == 'F', 0, data$gender))
str(data)
hist(data$hospital_death) ## trop de différence entre les 0 et les 1
head(data)
boston <- read.csv('https://raw.githubusercontent.com/JosueAfouda/Machine-Learning-par-la-pratique-avec-Python/master/Boston.csv')
head(boston)
# Installer les packages si nécessaire
install.packages("caret")
install.packages("ROSE")
# Charger les bibliothèques
library(caret)
library(ROSE)
# Spécifier la graine pour la reproductibilité
set.seed(123)
## melanger les lignes de fançons aléatoire  avec la fonction
head(data)
str(data)
rows<-sample(nrow(data))
data_mel <- data[rows,]
View(data_mel)
head(data_mel)
# Créer une partition stratifiée des données
index <- createDataPartition(data$hospital_death, p = 0.8, list = FALSE, times = 1)
# Séparer les données en ensembles d'entraînement et de test
train_data <- data[index, ]
test_data <- data[-index, ]
# Vérifier l'équilibre des classes dans l'ensemble d'entraînement
table(train_data$hospital_death)
# Effectuer un suréchantillonnage de la classe minoritaire avec ROS
library(ROSE)
# Obtenez la taille de la classe minoritaire dans l'échantillon d'entraînement
minority_size <- sum(train_data$hospital_death == 1)
# Obtenez la taille de l'échantillon initial
n <- nrow(train_data)
# Obtenez la taille de la classe minoritaire dans l'échantillon d'entraînement
minority_size <- sum(train_data$hospital_death == 1)
# Ajustez la valeur de N pour qu'elle soit supérieure ou égale à la taille de l'échantillon initial
N <- max(2 * minority_size, n)
# Utilisez ovun.sample en ajustant la valeur de N
rose_train_data <- ovun.sample(hospital_death ~ .,
data = train_data,
method = "over",
N = N,
seed = 123)$data
# Vérifier l'équilibre des classes après le suréchantillonnage
table(rose_train_data$hospital_death)
hist(rose_train_data$hospital_death)
train<- rose_train_data
odel <- glm(hospital_death ~ ., data = train_data, family = "binomial")
library(caret)
predictions <- predict(model, newdata = test_data, type = "response")
### Model GLM ########"
model <- glm(hospital_death ~ ., data = train_data, family = "binomial")
library(caret)
predictions <- predict(model, newdata = test_data, type = "response")
predictions_class <- ifelse(predictions > 0.5, 1, 0)
confusion_matrix <- confusionMatrix(table(predictions_class, test_data$hospital_death))
print(confusion_matrix)
# Installer le package pROC si nécessaire
# install.packages("pROC")
# Charger la bibliothèque
library(pROC)
# Obtenir les probabilités prédites du modèle pour la classe positive
predicted_probs <- predict(model, newdata = test_data, type = "response")
# Créer un objet de courbe ROC
roc_curve <- roc(test_data$hospital_death, predicted_probs)
# Afficher la courbe ROC
plot(roc_curve, main = "Courbe ROC", col = "blue", lwd = 2)
# Ajouter l'aire sous la courbe (AUC) au graphique
text(0.8, 0.2, paste("AUC =", round(auc(roc_curve), 3)), col = "blue")
# Afficher la légende
legend("bottomright", legend = paste("AUC =", round(auc(roc_curve), 3)), col = "blue", lty = 1, cex = 0.8)
# Calcul des métriques de la matrice de confusion
conf_matrix <- confusionMatrix(data = as.factor(predictions_class), reference = as.factor(test_data$hospital_death))
# Récupération des valeurs nécessaires pour le F1-score
TP <- conf_matrix$byClass[["Sensitivity"]] * conf_matrix$byClass[["Pos Pred Value"]]
FP <- (1 - conf_matrix$byClass[["Specificity"]]) * conf_matrix$byClass[["Neg Pred Value"]]
FN <- (1 - conf_matrix$byClass[["Sensitivity"]]) * conf_matrix$byClass[["Pos Pred Value"]]
# Calcul du F1-score
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)
# Affichage du score F1
print(paste("F1 Score:", round(f1_score, 3)))
